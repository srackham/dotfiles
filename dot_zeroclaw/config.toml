default_provider = "openrouter"
default_model = "minimax/minimax-m2.5"
api_key = "enc2:ec81e5d57ea716cf9806af44fa69835ffcfc9ebf775a862196da57159543615a9d1118a2d0aa43fbf8eafacd8a867a5ded60b883f9d51dbbd9276d1b295c7b0eda151f310d67a9152a79270f97d4d2f790c1143de0764d609d33b126c333c2ffc025df85ce"

# default_provider = "ollama"
# default_model = "minimax-m2.5:cloud"
# api_key = "enc2:51ffb9b557872e8f607460e68d78e67f8b2094d47f7d5c3555b6dc22ddacaf5a6d51c7dfead4ab3ff3677e8a2460cfb5486b1307ab058e8a4edea6b98fbd93397baba28f3a6df233fe6a04bd2ffeeec8701ccac259"
# api_url = "https://ollama.com"

default_temperature = 0.7
model_routes = []

[observability]
backend = "none"

[autonomy]
level = "supervised"
workspace_only = true
allowed_commands = [
    "git",
    "npm",
    "cargo",
    "ls",
    "cat",
    "grep",
    "find",
    "echo",
    "pwd",
    "wc",
    "head",
    "tail",
]
forbidden_paths = [
    "/etc",
    "/root",
    "/home",
    "/usr",
    "/bin",
    "/sbin",
    "/lib",
    "/opt",
    "/boot",
    "/dev",
    "/proc",
    "/sys",
    "/var",
    "/tmp",
    "~/.ssh",
    "~/.gnupg",
    "~/.aws",
    "~/.config",
]
max_actions_per_hour = 20
max_cost_per_day_cents = 500
require_approval_for_medium_risk = true
block_high_risk_commands = true
auto_approve = [
    "file_read",
    "memory_recall",
]
always_ask = []

[runtime]
kind = "native"

[runtime.docker]
image = "alpine:3.20"
network = "none"
memory_limit_mb = 512
cpu_limit = 1.0
read_only_rootfs = true
mount_workspace = true
allowed_workspace_roots = []

[reliability]
provider_retries = 2
provider_backoff_ms = 500
fallback_providers = []
api_keys = []
channel_initial_backoff_secs = 2
channel_max_backoff_secs = 60
scheduler_poll_secs = 15
scheduler_retries = 2

[reliability.model_fallbacks]

[scheduler]
enabled = true
max_tasks = 64
max_concurrent = 4

[agent]
compact_context = false
max_tool_iterations = 10
max_history_messages = 50
parallel_tools = false
tool_dispatcher = "auto"

[query_classification]
enabled = false
rules = []

[heartbeat]
enabled = false
interval_minutes = 30

[cron]
enabled = true
max_run_history = 50

[channels_config]
cli = true

[channels_config.telegram]
bot_token = "8448784146:AAHKqEEAs31hwYGvai8sQeo2fl-w7d1aptQ"
allowed_users = ["5237636637"]
stream_mode = "off"
draft_update_interval_ms = 1000
mention_only = false

[memory]
backend = "sqlite"
auto_save = true
hygiene_enabled = true
archive_after_days = 7
purge_after_days = 30
conversation_retention_days = 30
embedding_provider = "none"
embedding_model = "text-embedding-3-small"
embedding_dimensions = 1536
vector_weight = 0.7
keyword_weight = 0.3
min_relevance_score = 0.4
embedding_cache_size = 10000
chunk_max_tokens = 512
response_cache_enabled = false
response_cache_ttl_minutes = 60
response_cache_max_entries = 5000
snapshot_enabled = false
snapshot_on_hygiene = false
auto_hydrate = true

[storage.provider.config]
provider = ""
schema = "public"
table = "memories"

[tunnel]
provider = "none"

[gateway]
port = 3000
host = "127.0.0.1"
require_pairing = true
allow_public_bind = false
paired_tokens = []
pair_rate_limit_per_minute = 10
webhook_rate_limit_per_minute = 60
trust_forwarded_headers = false
rate_limit_max_keys = 10000
idempotency_ttl_secs = 300
idempotency_max_keys = 10000

[composio]
enabled = false
entity_id = "default"

[secrets]
encrypt = true

[browser]
enabled = false
allowed_domains = []
backend = "agent_browser"
native_headless = true
native_webdriver_url = "http://127.0.0.1:9515"

[browser.computer_use]
endpoint = "http://127.0.0.1:8787/v1/actions"
timeout_ms = 15000
allow_remote_endpoint = false
window_allowlist = []

[http_request]
enabled = false
allowed_domains = []
max_response_size = 0
timeout_secs = 0

[web_search]
enabled = true
provider = "duckduckgo"
max_results = 5
timeout_secs = 15

[proxy]
enabled = false
no_proxy = []
scope = "zeroclaw"
services = []

[identity]
format = "openclaw"

[cost]
enabled = false
daily_limit_usd = 10.0
monthly_limit_usd = 100.0
warn_at_percent = 80
allow_override = false

[cost.prices."google/gemini-1.5-pro"]
input = 1.25
output = 5.0

[cost.prices."openai/o1-preview"]
input = 15.0
output = 60.0

[cost.prices."anthropic/claude-sonnet-4-20250514"]
input = 3.0
output = 15.0

[cost.prices."openai/gpt-4o-mini"]
input = 0.15
output = 0.6

[cost.prices."openai/gpt-4o"]
input = 5.0
output = 15.0

[cost.prices."anthropic/claude-opus-4-20250514"]
input = 15.0
output = 75.0

[cost.prices."anthropic/claude-3-haiku"]
input = 0.25
output = 1.25

[cost.prices."anthropic/claude-3.5-sonnet"]
input = 3.0
output = 15.0

[cost.prices."google/gemini-2.0-flash"]
input = 0.1
output = 0.4

[peripherals]
enabled = false
boards = []

[agents]

[hardware]
enabled = true
transport = "Serial"
baud_rate = 115200
workspace_datasheets = true
